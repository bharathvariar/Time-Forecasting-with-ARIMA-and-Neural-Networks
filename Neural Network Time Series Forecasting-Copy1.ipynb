{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d3fc316",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pywrap_tensorflow' from partially initialized module 'tensorflow.python' (most likely due to a circular import) (C:\\Users\\bvari\\anaconda3\\envs\\python-datascience\\lib\\site-packages\\tensorflow\\python\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python-datascience\\lib\\site-packages\\keras\\__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python-datascience\\lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python-datascience\\lib\\site-packages\\keras\\engine\\functional.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layout_map \u001b[38;5;28;01mas\u001b[39;00m layout_map_lib\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python-datascience\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python-datascience\\lib\\site-packages\\tensorflow\\python\\__init__.py:36\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'pywrap_tensorflow' from partially initialized module 'tensorflow.python' (most likely due to a circular import) (C:\\Users\\bvari\\anaconda3\\envs\\python-datascience\\lib\\site-packages\\tensorflow\\python\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c48d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Active.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff43a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame((df[\"India\"].to_numpy()), columns = {'cases'})\n",
    "df.shape\n",
    "df = df.transform('sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6df0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df)\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6848401",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[-100:]\n",
    "train_df = df[:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac55c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2347f18",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5e5174",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe6d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf8d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    return round(mse, 3), round(mae, 3), round(mape, 3), round(rmse, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51490b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_keras_model(model, show_shapes=True, show_layer_names=True):\n",
    "    return SVG(model_to_dot(model, show_shapes=show_shapes, show_layer_names=show_layer_names).create(prog='dot',format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d4674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combinations(parameters):\n",
    "    return list(itertools.product(*parameters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6954b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_NN(input_nodes, hidden_nodes, output_nodes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(hidden_nodes), input_dim=int(input_nodes)))\n",
    "    model.add(Dense(int(output_nodes)))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ea421",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf7cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, epochs, batch_size):\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0, shuffle=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_arrays(X_train, y_train):\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54547462",
   "metadata": {},
   "source": [
    "## Feed Forward ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a8d752",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa989c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_FNN(data, look_back):\n",
    "    data = np.array(data)[:, 0]\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(data.shape[0]-look_back):\n",
    "        x = data[i:look_back+i][::-1]\n",
    "        y = data[look_back+i]\n",
    "        X_train.append(list(x))\n",
    "        y_train.append(y)\n",
    "    input_seq_for_test = data[i+1:look_back+i+1][::-1]\n",
    "    return X_train, y_train, input_seq_for_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d10dc",
   "metadata": {},
   "source": [
    "### Feed Forward ANN Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbfb499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_FNN(model, input_sequence, future_steps):\n",
    "    forecasted_values = []\n",
    "    for i in range(future_steps):\n",
    "        forecasted_value = model.predict(input_sequence)\n",
    "        forecasted_values.append(forecasted_value[0][0])\n",
    "        input_sequence[0] = np.append(forecasted_value, input_sequence[0][:-1])\n",
    "    return forecasted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a5ec29",
   "metadata": {},
   "source": [
    "### Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ccdd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FNN(data, look_back, hidden_nodes, output_nodes, epochs, batch_size, future_steps, scaler):\n",
    "    data = scaler.transform(data)\n",
    "    X_train, y_train, input_seq_for_test_FNN = preprocess_FNN(data, look_back)\n",
    "    X_train, y_train = reshape_arrays(X_train, y_train)\n",
    "\n",
    "    model_FNN = create_NN(input_nodes=look_back, hidden_nodes=hidden_nodes, output_nodes=output_nodes)\n",
    "    model_FNN = train_model(model_FNN, X_train, y_train, epochs, batch_size)\n",
    "\n",
    "    input_seq_for_test_FNN = np.reshape(input_seq_for_test_FNN, (1, len(input_seq_for_test_FNN)))\n",
    "    forecasted_values_FNN = forecast_FNN(model_FNN, input_sequence=input_seq_for_test_FNN, future_steps=future_steps)\n",
    "    \n",
    "    forecasted_values_FNN = list(scaler.inverse_transform([forecasted_values_FNN])[0])\n",
    "    \n",
    "    return model_FNN, forecasted_values_FNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de58b68f",
   "metadata": {},
   "source": [
    "### FNN scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5f4b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies_FNN(rainfall_data, test_rainfall_data, parameters, scaler):\n",
    "    combination_of_params = get_combinations(parameters)\n",
    "    information_FNN = []\n",
    "    iterator = 0\n",
    "    print('FNN - Number of combinations: ' + str(len(combination_of_params)))\n",
    "    \n",
    "    for param in combination_of_params:\n",
    "        if (iterator+1) != len(combination_of_params):\n",
    "            print(iterator+1, end=' -> ')\n",
    "        else:\n",
    "            print(iterator+1)\n",
    "        iterator = iterator+1\n",
    "\n",
    "        look_back = param[0]\n",
    "        hidden_nodes = param[1]\n",
    "        output_nodes = param[2]\n",
    "        epochs = param[3]\n",
    "        batch_size = param[4]\n",
    "        future_steps = param[5]\n",
    "\n",
    "        model_FNN, forecasted_values_FNN = FNN(rainfall_data, look_back, hidden_nodes, output_nodes, epochs, batch_size, future_steps, scaler)\n",
    "        \n",
    "        y_true = test_rainfall_data.iloc[:future_steps]\n",
    "        mse, mae, mape, rmse = calculate_performance(y_true, forecasted_values_FNN)\n",
    "        \n",
    "        info = list(param) + [mse, mae, rmse] + forecasted_values_FNN\n",
    "        information_FNN.append(info)\n",
    "\n",
    "    information_FNN_df = pd.DataFrame(information_FNN)\n",
    "    indexes = [str(i) for i in list(range(1, future_steps+1))]\n",
    "    information_FNN_df.columns = ['look_back', 'hidden_nodes', 'output_nodes', 'epochs', 'batch_size', 'future_steps', 'MSE', 'MAE', 'RMSE'] + indexes\n",
    "    return information_FNN_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56582179",
   "metadata": {},
   "source": [
    "## Time Lagged Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7820af83",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c875870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_TLNN(data, time_lagged_points):\n",
    "    data = np.array(data)[:, 0]\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(max(time_lagged_points), data.shape[0]):\n",
    "        x = [data[i-p] for p in time_lagged_points]\n",
    "        y = data[i]\n",
    "        X_train.append(list(x))\n",
    "        y_train.append(y)\n",
    "    input_seq_for_test = [data[i+1-p] for p in time_lagged_points]\n",
    "    return X_train, y_train, input_seq_for_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885edf7d",
   "metadata": {},
   "source": [
    "### TLNN Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e774e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_TLNN(model, time_lagged_points, last_sequence, future_steps):\n",
    "    forecasted_values = []\n",
    "    max_lag = max(time_lagged_points)\n",
    "    for i in range(future_steps):\n",
    "        input_sequence = [last_sequence[max_lag - p] for p in time_lagged_points]\n",
    "        forecasted_value = model.predict(np.reshape(input_sequence, (1, len(input_sequence))))\n",
    "        forecasted_values.append(forecasted_value[0][0])\n",
    "        last_sequence = last_sequence[1:] + [forecasted_value[0][0]]\n",
    "    return forecasted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76f9420",
   "metadata": {},
   "source": [
    "### Time Lagged Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae0aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TLNN(data, time_lagged_points, hidden_nodes, output_nodes, epochs, batch_size, future_steps, scaler):\n",
    "    data = scaler.transform(data)\n",
    "    X_train, y_train, input_seq_for_test_TLNN = preprocess_TLNN(data, time_lagged_points)\n",
    "    X_train, y_train = reshape_arrays(X_train, y_train)\n",
    "    model_TLNN = create_NN(input_nodes=len(time_lagged_points), hidden_nodes=hidden_nodes, output_nodes=output_nodes)\n",
    "    model_TLNN = train_model(model_TLNN, X_train, y_train, epochs, batch_size)\n",
    "\n",
    "    max_lag = max(time_lagged_points)\n",
    "    forecasted_values_TLNN = forecast_TLNN(model_TLNN, time_lagged_points, \n",
    "                                      list(data[-max_lag:]), future_steps=future_steps)\n",
    "    forecasted_values_TLNN = list(scaler.inverse_transform([forecasted_values_TLNN])[0])\n",
    "    \n",
    "    return model_TLNN, forecasted_values_TLNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0119ec67",
   "metadata": {},
   "source": [
    "### TLNN Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ff91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies_TLNN(rainfall_data, test_rainfall_data, parameters, scaler):\n",
    "    combination_of_params = get_combinations(parameters)\n",
    "    information_TLNN = []\n",
    "    iterator = 0\n",
    "    print('TLNN - Number of combinations: ' + str(len(combination_of_params)))\n",
    "    \n",
    "    for param in combination_of_params:\n",
    "        if (iterator+1) != len(combination_of_params):\n",
    "            print(iterator+1, end=' -> ')\n",
    "        else:\n",
    "            print(iterator+1)\n",
    "        iterator = iterator+1\n",
    "\n",
    "        time_lagged_points = param[0]\n",
    "        hidden_nodes = param[1]\n",
    "        output_nodes = param[2]\n",
    "        epochs = param[3]\n",
    "        batch_size = param[4]\n",
    "        future_steps = param[5]\n",
    "\n",
    "        model_TLNN, forecasted_values_TLNN = TLNN(rainfall_data, time_lagged_points, hidden_nodes, output_nodes, epochs, batch_size, future_steps, scaler)\n",
    "        \n",
    "        y_true = test_rainfall_data.iloc[:future_steps]\n",
    "        mse, mae, mape, rmse = calculate_performance(y_true, forecasted_values_TLNN)\n",
    "        \n",
    "        info = list(param) + [mse, mae, rmse] + forecasted_values_TLNN\n",
    "        information_TLNN.append(info)\n",
    "\n",
    "    information_TLNN_df = pd.DataFrame(information_TLNN)\n",
    "    indexes = [str(i) for i in list(range(1, future_steps+1))]\n",
    "    information_TLNN_df.columns = ['look_back_lags', 'hidden_nodes', 'output_nodes', 'epochs', 'batch_size', 'future_steps', 'MSE', 'MAE', 'RMSE'] + indexes\n",
    "    return information_TLNN_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7247a765",
   "metadata": {},
   "source": [
    "## Seasonal Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eb22a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_SANN(data, seasonal_period):\n",
    "    data = np.array(data)[:, 0]\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(seasonal_period, data.shape[0]-seasonal_period+1):\n",
    "        x = data[i-seasonal_period:i][::-1]\n",
    "        y = data[i:i+seasonal_period]\n",
    "        X_train.append(list(x))\n",
    "        y_train.append(list(y))\n",
    "    input_seq_for_test = data[i+1-seasonal_period:i+1][::-1]\n",
    "    return X_train, y_train, input_seq_for_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e98640",
   "metadata": {},
   "source": [
    "### SANN Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe356189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_SANN(model, input_sequence, seasonal_period, future_steps):\n",
    "    iterations = future_steps/seasonal_period\n",
    "    forecasted_values = []\n",
    "    for i in range(int(iterations) + 1):\n",
    "        next_forecasted_values = model.predict(input_sequence)\n",
    "        forecasted_values += list(next_forecasted_values[0])\n",
    "        input_sequence = next_forecasted_values\n",
    "    return forecasted_values[:future_steps]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b05588d",
   "metadata": {},
   "source": [
    "### SANN Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa564872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_SANN(model, input_sequence, seasonal_period, future_steps):\n",
    "    iterations = future_steps/seasonal_period\n",
    "    forecasted_values = []\n",
    "    for i in range(int(iterations) + 1):\n",
    "        next_forecasted_values = model.predict(input_sequence)\n",
    "        forecasted_values += list(next_forecasted_values[0])\n",
    "        input_sequence = next_forecasted_values\n",
    "    return forecasted_values[:future_steps]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f81aeba",
   "metadata": {},
   "source": [
    "### SANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb6074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SANN(data, seasonal_period, hidden_nodes, epochs, batch_size, future_steps, scaler):\n",
    "    data = scaler.transform(data)\n",
    "    X_train, y_train, input_seq_for_test_SANN = preprocess_SANN(data, seasonal_period)\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    input_seq_for_test_SANN = np.reshape(input_seq_for_test_SANN, (1, len(input_seq_for_test_SANN)))\n",
    "    model_SANN = create_NN(input_nodes=seasonal_period, hidden_nodes=hidden_nodes, output_nodes=seasonal_period)\n",
    "    model_SANN = train_model(model_SANN, X_train, y_train, epochs, batch_size)\n",
    "    \n",
    "    forecasted_values_SANN = forecast_SANN(model_SANN, input_seq_for_test_SANN, seasonal_period, future_steps=future_steps)\n",
    "    forecasted_values_SANN = list(scaler.inverse_transform([forecasted_values_SANN])[0])\n",
    "    return model_SANN, forecasted_values_SANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3f60db",
   "metadata": {},
   "source": [
    "### SANN Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6e4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies_SANN(rainfall_data, test_rainfall_data, parameters, scaler):\n",
    "    combination_of_params = get_combinations(parameters)\n",
    "    information_SANN = []\n",
    "    iterator = 0\n",
    "    print('SANN - Number of combinations: ' + str(len(combination_of_params)))\n",
    "    \n",
    "    for param in combination_of_params:\n",
    "        if (iterator+1) != len(combination_of_params):\n",
    "            print(iterator+1, end=' -> ')\n",
    "        else:\n",
    "            print(iterator+1)\n",
    "        iterator = iterator+1\n",
    "\n",
    "        seasonal_period = param[0]\n",
    "        hidden_nodes = param[1]\n",
    "        epochs = param[2]\n",
    "        batch_size = param[3]\n",
    "        future_steps = param[4]\n",
    "\n",
    "        model_SANN, forecasted_values_SANN = SANN(rainfall_data, seasonal_period, hidden_nodes, epochs, batch_size, future_steps, scaler)\n",
    "        \n",
    "        y_true = test_rainfall_data.iloc[:future_steps]\n",
    "        mse, mae, mape, rmse = calculate_performance(y_true, forecasted_values_SANN)\n",
    "        \n",
    "        info = list(param) + [mse, mae, rmse] + forecasted_values_SANN\n",
    "        information_SANN.append(info)\n",
    "\n",
    "    information_SANN_df = pd.DataFrame(information_SANN)\n",
    "    indexes = [str(i) for i in list(range(1, future_steps+1))]\n",
    "    information_SANN_df.columns = ['seasonal_period', 'hidden_nodes', 'epochs', 'batch_size', 'future_steps', 'MSE', 'MAE', 'RMSE'] + indexes\n",
    "    return information_SANN_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c6bf92",
   "metadata": {},
   "source": [
    "## Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed717d89",
   "metadata": {},
   "source": [
    "### LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f6544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LSTM(input_nodes, hidden_nodes, output_nodes):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_nodes, input_shape=(1, input_nodes)))\n",
    "    model.add(Dense(output_nodes))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d78413",
   "metadata": {},
   "source": [
    "### LSTM Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a2f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_LSTM(data, look_back):\n",
    "    data = np.array(data)[:, 0]\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(data.shape[0]-look_back):\n",
    "        x = data[i:look_back+i][::-1]\n",
    "        y = data[look_back+i]\n",
    "        X_train.append(list(x))\n",
    "        y_train.append(y)\n",
    "    input_seq_for_test = data[i+1:look_back+i+1][::-1]\n",
    "    return X_train, y_train, input_seq_for_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc16dda",
   "metadata": {},
   "source": [
    "### LSTM Forecasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a96c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_LSTM(model, input_sequence, future_steps):\n",
    "    forecasted_values = []\n",
    "    for i in range(future_steps):\n",
    "        forecasted_value = model.predict(input_sequence)\n",
    "        forecasted_values.append(forecasted_value[0][0])\n",
    "        input_sequence[0][0] = np.append(forecasted_value, input_sequence[0][0][:-1])\n",
    "    return forecasted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad36dc",
   "metadata": {},
   "source": [
    "### Long Short Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771fa82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Long_Short_Term_Memory(data, look_back, hidden_nodes, output_nodes, epochs, batch_size, future_steps, scaler):\n",
    "    data = scaler.transform(data)\n",
    "    X_train, y_train, input_seq_for_test_LSTM = preprocess_LSTM(data, look_back)\n",
    "    X_train = np.reshape(X_train, (len(X_train), 1, look_back))\n",
    "\n",
    "    model_LSTM = create_LSTM(input_nodes=look_back, hidden_nodes=hidden_nodes, output_nodes=output_nodes)\n",
    "    #plot_keras_model(model_LSTM)\n",
    "    model_LSTM = train_model(model_LSTM, X_train, y_train, epochs, batch_size)\n",
    "\n",
    "    input_seq_for_test_LSTM = np.reshape(input_seq_for_test_LSTM, (1, 1, len(input_seq_for_test_LSTM)))\n",
    "    forecasted_values_LSTM = forecast_LSTM(model_LSTM, input_sequence=input_seq_for_test_LSTM, future_steps=future_steps)\n",
    "    \n",
    "    forecasted_values_LSTM = list(scaler.inverse_transform([forecasted_values_LSTM])[0])\n",
    "    \n",
    "    return model_LSTM, forecasted_values_LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd0fe5",
   "metadata": {},
   "source": [
    "### LSTM scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47724627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies_LSTM(rainfall_data, test_rainfall_data, parameters, scaler):\n",
    "    combination_of_params = get_combinations(parameters)\n",
    "    information_LSTM = []\n",
    "    iterator = 0\n",
    "    print('LSTM - Number of combinations: ' + str(len(combination_of_params)))\n",
    "    \n",
    "    for param in combination_of_params:\n",
    "        if (iterator+1) != len(combination_of_params):\n",
    "            print(iterator+1, end=' -> ')\n",
    "        else:\n",
    "            print(iterator+1)\n",
    "        iterator = iterator+1\n",
    "\n",
    "        input_nodes = param[0]\n",
    "        hidden_nodes = param[1]\n",
    "        output_nodes = param[2]\n",
    "        epochs = param[3]\n",
    "        batch_size = param[4]\n",
    "        future_steps = param[5]\n",
    "\n",
    "        model_LSTM, forecasted_values_LSTM = Long_Short_Term_Memory(rainfall_data, input_nodes, hidden_nodes, output_nodes, epochs, batch_size, future_steps, scaler)\n",
    "        \n",
    "        y_true = test_rainfall_data.iloc[:future_steps]\n",
    "        mse, mae, mape, rmse = calculate_performance(y_true, forecasted_values_LSTM)\n",
    "        \n",
    "        info = list(param) + [mse, mae, rmse] + forecasted_values_LSTM\n",
    "        information_LSTM.append(info)\n",
    "\n",
    "    information_LSTM_df = pd.DataFrame(information_LSTM)\n",
    "    indexes = [str(i) for i in list(range(1, future_steps+1))]\n",
    "    information_LSTM_df.columns = ['look_back', 'hidden_nodes', 'output_nodes', 'epochs', 'batch_size', 'future_steps', 'MSE', 'MAE', 'RMSE'] + indexes\n",
    "    return information_LSTM_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02f931",
   "metadata": {},
   "source": [
    "### Analyze the test data and forecasted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(data_frame, test_rainfall_data, name, flag=False):\n",
    "    optimized_params = data_frame.iloc[data_frame.RMSE.argmin()]\n",
    "    future_steps = optimized_params.future_steps\n",
    "    forecast_values = optimized_params[-1*int(future_steps):]\n",
    "    y_true = test_rainfall_data.iloc[:int(future_steps)]\n",
    "    forecast_values.index = y_true.index\n",
    "    \n",
    "    print('=== Best parameters of ' + name + ' ===\\n')\n",
    "    if (name == 'FNN' or name == 'LSTM'):\n",
    "        model = create_NN(optimized_params.look_back, \n",
    "                          optimized_params.hidden_nodes, \n",
    "                          optimized_params.output_nodes)\n",
    "        print('Input nodes(p): ' + str(optimized_params.look_back))\n",
    "        print('Hidden nodes: ' + str(optimized_params.hidden_nodes))\n",
    "        print('Output nodes: ' + str(optimized_params.output_nodes))\n",
    "    elif (name == 'TLNN'):\n",
    "        model = create_NN(len(optimized_params.look_back_lags), \n",
    "                          optimized_params.hidden_nodes, \n",
    "                          optimized_params.output_nodes)\n",
    "        s = ''\n",
    "        for i in optimized_params.look_back_lags:\n",
    "            s = s+' '+str(i)\n",
    "        print('Look back lags: ' + s)\n",
    "        print('Hidden nodes: ' + str(optimized_params.hidden_nodes))\n",
    "        print('Output nodes: ' + str(optimized_params.output_nodes))\n",
    "    elif (name == 'SANN'):\n",
    "        model = create_NN(optimized_params.seasonal_period, \n",
    "                          optimized_params.hidden_nodes, \n",
    "                          optimized_params.seasonal_period)\n",
    "        print('Input nodes(s): ' + str(optimized_params.seasonal_period))\n",
    "        print('Hidden nodes: ' + str(optimized_params.hidden_nodes))\n",
    "        print('Output nodes: ' + str(optimized_params.seasonal_period))\n",
    "        \n",
    "    print('Number of epochs: ' + str(optimized_params.epochs))\n",
    "    print('Batch size: ' + str(optimized_params.batch_size))\n",
    "    print('Number of future steps forecasted: ' + str(optimized_params.future_steps))\n",
    "    print('Mean Squared Error(MSE): ' + str(optimized_params.MSE))\n",
    "    print('Mean Absolute Error(MAE): ' + str(optimized_params.MAE))\n",
    "    print('Root Mean Squared Error(RMSE): ' + str(optimized_params.RMSE))\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    # Save model\n",
    "    from keras.utils import plot_model\n",
    "#     plot_model(model, to_file = STORAGE_FOLDER + name + '_best_fit_model.png', show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "#     # Save data\n",
    "#     data_frame.to_csv(STORAGE_FOLDER + name + '_information.csv')\n",
    "#     optimized_params.to_csv(STORAGE_FOLDER + name + '_optimized_values.csv')\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(y_true, color='green', label='Actual values')\n",
    "    plt.plot(forecast_values, color='red', label='Forecasted values')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Monthly mean Precipitation')\n",
    "    plt.legend(loc='best')\n",
    "    if (flag==False):\n",
    "        plt.title(name + ' - Comaprison: Actual vs Forecasted')\n",
    "#         plt.savefig(STORAGE_FOLDER + name + '_best_forecast'  + '.png')\n",
    "    else:\n",
    "        plt.title('Best of all: ' + name + ' - Comaprison: Actual vs Forecasted')\n",
    "#         plt.savefig(STORAGE_FOLDER + 'BEST_FORECAST_' + name + '.png')\n",
    "    \n",
    "    return optimized_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afa40ca",
   "metadata": {},
   "source": [
    "### Pick the Best Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79662e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_of_all(list_of_methods):\n",
    "    RMSE_values = [x.RMSE for x in list_of_methods]\n",
    "    index = np.argmin(RMSE_values)\n",
    "    if (index==0):\n",
    "        name = 'FNN'\n",
    "    elif (index == 1):\n",
    "        name = 'TLNN'\n",
    "    elif (index == 2):\n",
    "        name = 'SANN'\n",
    "    else:\n",
    "        name = 'LSTM'\n",
    "    print(RMSE_values)\n",
    "    \n",
    "    names = ['FNN', 'TLNN', 'SANN', 'LSTM']\n",
    "    RMSE_info = pd.Series(RMSE_values, index=names)\n",
    "    \n",
    "    print('Overall Best method on this data is ' + name)\n",
    "    return index, name, RMSE_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c6bc65",
   "metadata": {},
   "source": [
    "### Compare Results of above algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab72b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_ANN_methods(rainfall_data, test_rainfall_data, scaler, parameters_FNN, parameters_TLNN, parameters_SANN, parameters_LSTM, future_steps):\n",
    "    \n",
    "    information_FNN_df = get_accuracies_FNN(rainfall_data, test_rainfall_data, parameters_FNN, scaler)\n",
    "    optimized_params_FNN = analyze_results(information_FNN_df, test_rainfall_data, 'FNN')\n",
    "    \n",
    "    #information_TLNN_df = get_accuracies_TLNN(rainfall_data, test_rainfall_data, parameters_TLNN, scaler)\n",
    "    #optimized_params_TLNN = analyze_results(information_TLNN_df, test_rainfall_data, 'TLNN')\n",
    "    \n",
    "    #information_SANN_df = get_accuracies_SANN(rainfall_data, test_rainfall_data, parameters_SANN, scaler)\n",
    "     #optimized_params_SANN = analyze_results(information_SANN_df, test_rainfall_data, 'SANN')\n",
    "    \n",
    "    #information_LSTM_df = get_accuracies_LSTM(rainfall_data, test_rainfall_data, parameters_LSTM, scaler)\n",
    "    #optimized_params_LSTM = analyze_results(information_LSTM_df, test_rainfall_data, 'LSTM')\n",
    "    \n",
    "    list_of_methods = [optimized_params_FNN, optimized_params_TLNN, optimized_params_SANN, optimized_params_LSTM]\n",
    "    information = [information_FNN_df, information_TLNN_df, information_SANN_df, information_LSTM_df]\n",
    "    index, name, RMSE_info = best_of_all(list_of_methods)\n",
    "    best_optimized_params = analyze_results(information[index], test_rainfall_data, name, True)\n",
    "    return RMSE_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b7484c",
   "metadata": {},
   "source": [
    "### Number of Future steps to be forecasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8398b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_steps =100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58e6dd2",
   "metadata": {},
   "source": [
    "### Initialize all the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e67482",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# look_back, hidden_nodes, output_nodes, epochs, batch_size, future_steps\n",
    "parameters_FNN = [[1,2,3,6,8,10,12], [3,4,5,6], [1], [500], [20], [future_steps]]\n",
    "\n",
    "# time_lagged_points, hidden_nodes, output_nodes, epochs, batch_size, future_steps\n",
    "parameters_TLNN = [[[1,2,3,11,12], [1,2,3,4,11,12], [1,2,3,11,12,13], [1,2,3,4,5,6,10,11,12]], [3,4,5,6], [1], [300], [20], [future_steps]]\n",
    "\n",
    "# seasonal_period, hidden_nodes, epochs, batch_size, future_steps\n",
    "parameters_SANN = [[12], [3,4,5,6,7,8,9,10], [500], [20], [future_steps]]\n",
    "\n",
    "# look_back, hidden_nodes, output_nodes, epochs, batch_size, future_steps\n",
    "parameters_LSTM = [[1,2,3,4,5,6,7,8,9,10,11,12,13], [3,4,5,6], [1], [300], [20], [future_steps]]\n",
    "\n",
    "\n",
    "RMSE_info = compare_ANN_methods(train_df, test_df, scaler, \n",
    "                    parameters_FNN, parameters_TLNN, parameters_SANN, parameters_LSTM, future_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1bfe71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1ebd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
